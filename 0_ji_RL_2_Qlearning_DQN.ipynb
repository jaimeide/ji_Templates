{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great References to study deeper:\n",
    "\n",
    "- David Silver (DeepMind)\n",
    "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html\n",
    "- Richard Sutton\n",
    "http://incompleteideas.net/book/the-book-2nd.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In WinEluk use environment \"cvision\"\n",
    "# In Valta use root environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Simple Neural Net in Pytorch\n",
    "\n",
    "- Really toy problem: just fit a line...\n",
    "- Code still works for torch 0.4.0\n",
    "- Atamai Lec#31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 0.4.0\n",
      "Cuda:  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "print('torch version:',torch.__version__)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Cuda: ', use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  torch.Size([100, 1])\n",
      "Episode 0, loss 7786.1187 \n",
      "Episode 50, loss 3656.6931 \n",
      "Episode 100, loss 1441.9728 \n",
      "Episode 150, loss 470.8453 \n",
      "Episode 200, loss 124.9038 \n",
      "Episode 250, loss 26.7249 \n",
      "Episode 300, loss 4.7129 \n",
      "Episode 350, loss 0.8218 \n",
      "Episode 400, loss 0.2792 \n",
      "Episode 450, loss 0.2184 \n",
      "Episode 500, loss 0.2113 \n",
      "Episode 550, loss 0.2087 \n",
      "Episode 600, loss 0.2062 \n",
      "Episode 650, loss 0.2037 \n",
      "Episode 700, loss 0.2011 \n",
      "Episode 750, loss 0.1984 \n",
      "Episode 800, loss 0.1956 \n",
      "Episode 850, loss 0.1927 \n",
      "Episode 900, loss 0.1898 \n",
      "Episode 950, loss 0.1867 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAFACAYAAAB3BVA7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f66e6b752b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if gpu is to be used\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "W = 2\n",
    "b = 0.3\n",
    "\n",
    "x = Variable(torch.arange(100).unsqueeze(1)) # To get tensor [100,1]\n",
    "print('x shape: ',x.shape)\n",
    "#x = Variable(torch.arange(100)) # this will not work because it produces a tensor [100]\n",
    "\n",
    "if use_cuda:\n",
    "    x = x.cuda()\n",
    "\n",
    "y = W * x + b\n",
    "\n",
    "###### PARAMS ######\n",
    "learning_rate = 0.01\n",
    "num_episodes = 1000\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(1,1) # out = w*x + bias\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.linear1(x)\n",
    "        return output\n",
    "    \n",
    "mynn = NeuralNetwork()\n",
    "\n",
    "if use_cuda:\n",
    "    mynn.cuda()\n",
    "    \n",
    "loss_func = nn.MSELoss()\n",
    "#loss_func = nn.SmoothL1Loss()\n",
    "\n",
    "optimizer = optim.Adam(params=mynn.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.RMSprop(params=mynn.parameters(), lr=learning_rate)\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    \n",
    "    predicted_value = mynn(x)\n",
    "    \n",
    "    loss = loss_func(predicted_value, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i_episode % 50 == 0:\n",
    "        #print(\"Episode %i, loss %.4f \" % (i_episode, loss.data[0]))\n",
    "        print(\"Episode %i, loss %.4f \" % (i_episode, loss.data.item()))\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(x.data.cpu().numpy(), y.data.cpu().numpy(), alpha=0.6, color='green')\n",
    "plt.plot(x.data.cpu().numpy(), predicted_value.data.cpu().numpy(), alpha=0.6, color='red')\n",
    "plt.xlabel('x'), plt.ylabel('y')\n",
    "plt.legend(['original','predicted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CartPole-v0: \"Q-learning\" + Neural Net (simple Linear regression)\n",
    "\n",
    "- Neural net will work as a function F, where action = F(state)\n",
    "- GOAL: be able to keep the pole for >195 steps, that is, reward>195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\n",
      "*** Episode 0 ***                 \n",
      " Avg.Reward [last 500]: 0.03, [last 100]: 0.14, [all]: 14.00                \n",
      " epsilon: 0.88, cont_steps= 14\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 500 ***                 \n",
      " Avg.Reward [last 500]: 10.05, [last 100]: 9.43, [all]: 10.06                \n",
      " epsilon: 0.02, cont_steps= 5038\n",
      "Elapsed time:  00:00:07\n",
      "\n",
      "*** Episode 1000 ***                 \n",
      " Avg.Reward [last 500]: 13.75, [last 100]: 23.80, [all]: 11.90                \n",
      " epsilon: 0.02, cont_steps= 11912\n",
      "Elapsed time:  00:00:17\n",
      "\n",
      "*** Episode 1500 ***                 \n",
      " Avg.Reward [last 500]: 26.43, [last 100]: 30.02, [all]: 16.74                \n",
      " epsilon: 0.02, cont_steps= 25128\n",
      "Elapsed time:  00:00:33\n",
      "\n",
      "*** Episode 2000 ***                 \n",
      " Avg.Reward [last 500]: 26.35, [last 100]: 24.92, [all]: 19.14                \n",
      " epsilon: 0.02, cont_steps= 38301\n",
      "Elapsed time:  00:00:47\n",
      "\n",
      "*** Episode 2500 ***                 \n",
      " Avg.Reward [last 500]: 24.13, [last 100]: 21.35, [all]: 20.14                \n",
      " epsilon: 0.02, cont_steps= 50364\n",
      "Elapsed time:  00:01:03\n",
      "\n",
      "*** Episode 3000 ***                 \n",
      " Avg.Reward [last 500]: 26.77, [last 100]: 21.96, [all]: 21.24                \n",
      " epsilon: 0.02, cont_steps= 63749\n",
      "Elapsed time:  00:01:24\n",
      "\n",
      "*** Episode 3500 ***                 \n",
      " Avg.Reward [last 500]: 26.27, [last 100]: 24.47, [all]: 21.96                \n",
      " epsilon: 0.02, cont_steps= 76885\n",
      "Elapsed time:  00:01:41\n",
      "\n",
      "*** Episode 4000 ***                 \n",
      " Avg.Reward [last 500]: 25.38, [last 100]: 24.81, [all]: 22.39                \n",
      " epsilon: 0.02, cont_steps= 89576\n",
      "Elapsed time:  00:02:01\n",
      "\n",
      "*** Episode 4500 ***                 \n",
      " Avg.Reward [last 500]: 24.24, [last 100]: 27.81, [all]: 22.59                \n",
      " epsilon: 0.02, cont_steps= 101696\n",
      "Elapsed time:  00:02:19\n",
      "\n",
      "*** Episode 5000 ***                 \n",
      " Avg.Reward [last 500]: 28.79, [last 100]: 30.08, [all]: 23.21                \n",
      " epsilon: 0.02, cont_steps= 116092\n",
      "Elapsed time:  00:02:42\n",
      "\n",
      "*** Episode 5500 ***                 \n",
      " Avg.Reward [last 500]: 26.35, [last 100]: 27.36, [all]: 23.50                \n",
      " epsilon: 0.02, cont_steps= 129266\n",
      "Elapsed time:  00:03:02\n",
      "\n",
      "*** Episode 6000 ***                 \n",
      " Avg.Reward [last 500]: 24.65, [last 100]: 23.33, [all]: 23.59                \n",
      " epsilon: 0.02, cont_steps= 141591\n",
      "Elapsed time:  00:03:17\n",
      "\n",
      "*** Episode 6500 ***                 \n",
      " Avg.Reward [last 500]: 22.50, [last 100]: 20.29, [all]: 23.51                \n",
      " epsilon: 0.02, cont_steps= 152840\n",
      "Elapsed time:  00:03:33\n",
      "\n",
      "*** Episode 7000 ***                 \n",
      " Avg.Reward [last 500]: 21.64, [last 100]: 19.55, [all]: 23.38                \n",
      " epsilon: 0.02, cont_steps= 163661\n",
      "Elapsed time:  00:03:49\n",
      "\n",
      "*** Episode 7500 ***                 \n",
      " Avg.Reward [last 500]: 17.72, [last 100]: 31.68, [all]: 23.00                \n",
      " epsilon: 0.02, cont_steps= 172520\n",
      "Elapsed time:  00:04:01\n",
      "\n",
      "*** Episode 8000 ***                 \n",
      " Avg.Reward [last 500]: 14.51, [last 100]: 21.66, [all]: 22.47                \n",
      " epsilon: 0.02, cont_steps= 179773\n",
      "Elapsed time:  00:04:12\n",
      "\n",
      "*** Episode 8500 ***                 \n",
      " Avg.Reward [last 500]: 22.20, [last 100]: 22.50, [all]: 22.45                \n",
      " epsilon: 0.02, cont_steps= 190875\n",
      "Elapsed time:  00:04:25\n",
      "\n",
      "*** Episode 9000 ***                 \n",
      " Avg.Reward [last 500]: 22.73, [last 100]: 29.79, [all]: 22.47                \n",
      " epsilon: 0.02, cont_steps= 202242\n",
      "Elapsed time:  00:04:44\n",
      "\n",
      "*** Episode 9500 ***                 \n",
      " Avg.Reward [last 500]: 20.72, [last 100]: 22.13, [all]: 22.38                \n",
      " epsilon: 0.02, cont_steps= 212603\n",
      "Elapsed time:  00:04:58\n",
      "Average reward: 22.58\n",
      "Average reward (last 100 episodes): 24.90\n",
      "Number of solved times:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAE/CAYAAAC0Fl50AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff29566ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Debug mode\n",
    "debug = False\n",
    "\n",
    "# Set CPU or GPU device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\") \n",
    "\n",
    "# Set Gym environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Set seeds\n",
    "seed_value = 23\n",
    "env.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "# PARAMS\n",
    "num_episodes = 10000\n",
    "gamma = 0.85\n",
    "my_lr = 0.01\n",
    "score_goal = 195 # official\n",
    "\n",
    "egreedy = 0.9\n",
    "egreedy_final = 0.02\n",
    "egreedy_decay = 500\n",
    "\n",
    "# e-Greedy strategy\n",
    "def calc_epsilon(nsteps):\n",
    "    epsilon = egreedy_final + \\\n",
    "       (egreedy - egreedy_final)*math.exp(-1.*nsteps/egreedy_decay) \n",
    "    return epsilon\n",
    "\n",
    "# NEURAL NETWORK\n",
    "n_inputs = env.observation_space.shape[0] \n",
    "n_outputs = env.action_space.n\n",
    "\n",
    "# 1) Define the NN architecture\n",
    "class NeuralNet(nn.Module): # self inherits the class nn.Module\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__() # Call parent's init\n",
    "        self.linear1 = nn.Linear(n_inputs,n_outputs) # simple layer\n",
    "        \n",
    "    def forward(self,x):\n",
    "        output = self.linear1(x)\n",
    "        return output\n",
    "    \n",
    "# 2) Define the NN-agent\n",
    "class Qnet_agent():\n",
    "    # 1) Init\n",
    "    def __init__(self):\n",
    "        # a) Architecture\n",
    "        self.nn = NeuralNet().to(device)\n",
    "        # b) Loss\n",
    "        self.loss = nn.MSELoss() # linear regression\n",
    "        # c) Optim\n",
    "        self.optimizer = optim.Adam(params=self.nn.parameters(),lr=my_lr)\n",
    "        \n",
    "    # 2) Action\n",
    "    def select_action(self,state,epsilon):\n",
    "        # e-greedy with Exploit x Explore trade-off\n",
    "        randx = torch.rand(1)[0]\n",
    "        \n",
    "        if randx > epsilon:\n",
    "            # Exploit\n",
    "            with torch.no_grad(): # more efficient than detach()\n",
    "                state = torch.Tensor(state).to(device)\n",
    "                action_from_nn = self.nn(state)\n",
    "                action_index = torch.max(action_from_nn,0)[1] # 1 for the index\n",
    "                action = action_index.item()\n",
    "                \n",
    "                if debug:\n",
    "                    print('--> Exploit action_from_nn[',action_from_nn,'] action:',action)\n",
    "        else:\n",
    "            # Explore\n",
    "            action = env.action_space.sample()\n",
    "            if debug:\n",
    "                print('--> Explore: action:',action)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    # 3) Optimize\n",
    "    def optimize(self,state,action,new_state,reward,done):\n",
    "        # - Variable and Tensor are identical classes\n",
    "        state = torch.Tensor(state).to(device) # Convert to tensor\n",
    "        new_state = torch.Tensor(new_state).to(device)\n",
    "        reward = torch.Tensor([reward]).to(device) # since others are list, reward has to be in list format\n",
    "        \n",
    "        if done:\n",
    "            target_value = reward # episode is completed\n",
    "        else:\n",
    "            ## Bellman's equation (- Traditional way -)\n",
    "            # Q[state,action] = reward + gamma*torch.max(Q[new_state])\n",
    "        \n",
    "            # We will use NNet instead to Approx Q (- New way -)\n",
    "            new_state_values = self.nn(new_state).detach() # leave the grad\n",
    "            max_new_state_values = torch.max(new_state_values)\n",
    "            target_value = reward + gamma*max_new_state_values\n",
    "        \n",
    "        ## Q-learning: use prediction-error to update Q\n",
    "        # (-- Traditional way --)\n",
    "        # Q[state, action] = (1 - lr) * Q[state, action] \\\n",
    "        #    + lr * (reward + gamma * torch.max(Q[new_state]))\n",
    "        # (-- New way --)    \n",
    "        # Current state\n",
    "        predicted_value = self.nn(state)[action] # here we carry grad because it will update\n",
    "        # Prediction error\n",
    "        loss = self.loss(predicted_value,target_value)\n",
    "        # Backprop\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step() # update params\n",
    "        \n",
    "\n",
    "# 3) RL part\n",
    "agent = Qnet_agent()\n",
    "steps_total = []\n",
    "all_solved_nepisodes = []\n",
    "cont_steps = 0\n",
    "tic = time.time()\n",
    "for i_episode in range(num_episodes):\n",
    "    \n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        cont_steps += 1 # will keep across episodes\n",
    "        epsilon = calc_epsilon(cont_steps) \n",
    "        \n",
    "        # Action is selected\n",
    "        action = agent.select_action(state,epsilon)\n",
    "        \n",
    "        # Next environment\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        # States: [cart position,cart velocity,pole angle, pole velocity]\n",
    "        \n",
    "        # Update NNet\n",
    "        agent.optimize(state,action,new_state,reward,done)\n",
    "        \n",
    "        if debug:\n",
    "            print('Step#%d: %s, state:%s'%(step,action,new_state))\n",
    "            #print(info)\n",
    "            env.render()\n",
    "            input(\"\")\n",
    "        \n",
    "        # Prepare next iteration\n",
    "        state = new_state\n",
    "        \n",
    "        if done:\n",
    "            steps_total.append(step)\n",
    "            #print(\"Episode finished after %i steps\" % step )\n",
    "            \n",
    "            avgReward100 = sum(steps_total[-100:])/100\n",
    "            \n",
    "            if avgReward100 > score_goal:\n",
    "                print('SOLVED! After %d episodes' %(i_episode))\n",
    "                all_solved_nepisodes.append(i_episodes)\n",
    "                \n",
    "                break\n",
    "            \n",
    "            # Better reporting\n",
    "            interval = 500\n",
    "            if i_episode % interval == 0:\n",
    "                print('\\n*** Episode %i *** \\\n",
    "                \\n Avg.Reward [last %i]: %.2f, [last 100]: %.2f, [all]: %.2f\\\n",
    "                \\n epsilon: %.2f, cont_steps= %d'%\n",
    "                      (i_episode, interval,\n",
    "                      sum(steps_total[-interval:])/interval,\n",
    "                      avgReward100,\n",
    "                      sum(steps_total)/len(steps_total),\n",
    "                       epsilon, cont_steps\n",
    "                      ))\n",
    "                toc = time.time()\n",
    "                print(\"Elapsed time: \", time.strftime(\"%H:%M:%S\", time.gmtime(toc-tic)))\n",
    "            \n",
    "            break\n",
    "        \n",
    "\n",
    "print(\"Average reward: %.2f\" % (sum(steps_total)/num_episodes))\n",
    "print(\"Average reward (last 100 episodes): %.2f\" % (sum(steps_total[-100:])/100))\n",
    "print(\"Number of solved times: \", len(all_solved_nepisodes))\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title(\"Rewards\")\n",
    "plt.bar(torch.arange(len(steps_total)), steps_total, alpha=0.6, color='green')\n",
    "plt.show()\n",
    "\n",
    "env.close()\n",
    "env.env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CartPole-v0: \"Q-learning\" + Neural Net (2 layers)\n",
    "\n",
    "- We will add 1 additional layers to input some non-linearity\n",
    "- Neural net will work as a function F, where action = F(state)\n",
    "- GOAL: be able to keep the pole for >195 steps, that is, reward>195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\n",
      "*** Episode 0 ***                 \n",
      " Avg.Reward [last 50]: 0.38, [last 100]: 0.19, [all]: 19.00                \n",
      " epsilon: 0.87, cont_steps= 19\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 50 ***                 \n",
      " Avg.Reward [last 50]: 38.12, [last 100]: 19.25, [all]: 37.75                \n",
      " epsilon: 0.04, cont_steps= 1925\n",
      "Elapsed time:  00:00:04\n",
      "\n",
      "*** Episode 100 ***                 \n",
      " Avg.Reward [last 50]: 95.76, [last 100]: 66.94, [all]: 66.47                \n",
      " epsilon: 0.02, cont_steps= 6713\n",
      "Elapsed time:  00:00:14\n",
      "\n",
      "*** Episode 150 ***                 \n",
      " Avg.Reward [last 50]: 152.46, [last 100]: 124.11, [all]: 94.94                \n",
      " epsilon: 0.02, cont_steps= 14336\n",
      "Elapsed time:  00:00:28\n",
      "\n",
      "*** Episode 200 ***                 \n",
      " Avg.Reward [last 50]: 167.10, [last 100]: 159.78, [all]: 112.89                \n",
      " epsilon: 0.02, cont_steps= 22691\n",
      "Elapsed time:  00:00:45\n",
      "\n",
      "*** Episode 250 ***                 \n",
      " Avg.Reward [last 50]: 162.16, [last 100]: 164.63, [all]: 122.71                \n",
      " epsilon: 0.02, cont_steps= 30799\n",
      "Elapsed time:  00:01:01\n",
      "\n",
      "*** Episode 300 ***                 \n",
      " Avg.Reward [last 50]: 181.92, [last 100]: 172.04, [all]: 132.54                \n",
      " epsilon: 0.02, cont_steps= 39895\n",
      "Elapsed time:  00:01:15\n",
      "\n",
      "*** Episode 350 ***                 \n",
      " Avg.Reward [last 50]: 182.42, [last 100]: 182.17, [all]: 139.65                \n",
      " epsilon: 0.02, cont_steps= 49016\n",
      "Elapsed time:  00:01:31\n",
      "\n",
      "*** Episode 400 ***                 \n",
      " Avg.Reward [last 50]: 181.32, [last 100]: 181.87, [all]: 144.84                \n",
      " epsilon: 0.02, cont_steps= 58082\n",
      "Elapsed time:  00:01:47\n",
      "\n",
      "*** Episode 450 ***                 \n",
      " Avg.Reward [last 50]: 181.08, [last 100]: 181.20, [all]: 148.86                \n",
      " epsilon: 0.02, cont_steps= 67136\n",
      "Elapsed time:  00:02:03\n",
      "Average reward: 150.49\n",
      "Average reward (last 100 episodes): 173.63\n",
      "Number of solved times:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAE/CAYAAAC0Fl50AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff292c757f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Debug mode\n",
    "debug = False\n",
    "\n",
    "# Set CPU or GPU device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\") \n",
    "\n",
    "# Set Gym environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Set seeds\n",
    "seed_value = 23\n",
    "env.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "# PARAMS\n",
    "num_episodes = 500\n",
    "score_goal = 195 # official\n",
    "\n",
    "gamma = 0.99\n",
    "my_lr = 0.02\n",
    "nhidden = 64\n",
    "\n",
    "egreedy = 0.9\n",
    "egreedy_final = 0.02\n",
    "egreedy_decay = 500\n",
    "\n",
    "# e-Greedy strategy\n",
    "def calc_epsilon(nsteps):\n",
    "    epsilon = egreedy_final + \\\n",
    "       (egreedy - egreedy_final)*math.exp(-1.*nsteps/egreedy_decay) \n",
    "    return epsilon\n",
    "\n",
    "# NEURAL NETWORK\n",
    "n_inputs = env.observation_space.shape[0] \n",
    "n_outputs = env.action_space.n\n",
    "\n",
    "# 1) Define the NN architecture\n",
    "class NeuralNet(nn.Module): # self inherits the class nn.Module\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__() # Call parent's init\n",
    "        self.linear1 = nn.Linear(n_inputs,nhidden) # input\n",
    "        self.linear2 = nn.Linear(nhidden,n_outputs) # layer 2\n",
    "        \n",
    "        self.activation = nn.Tanh()\n",
    "        #self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        output1 = self.linear1(x)\n",
    "        output1 = self.activation(output1)\n",
    "        output2 = self.linear2(output1)\n",
    "        #output2 = self.activation(output2)\n",
    "        #output3 = self.linear3(output2)\n",
    "        \n",
    "        return output2\n",
    "    \n",
    "# 2) Define the NN-agent\n",
    "class Qnet_agent():\n",
    "    # 1) Init\n",
    "    def __init__(self):\n",
    "        # a) Architecture\n",
    "        self.nn = NeuralNet().to(device)\n",
    "        # b) Loss\n",
    "        self.loss = nn.MSELoss() # linear regression\n",
    "        # c) Optim\n",
    "        self.optimizer = optim.Adam(params=self.nn.parameters(),lr=my_lr)\n",
    "        \n",
    "    # 2) Action\n",
    "    def select_action(self,state,epsilon):\n",
    "        # e-greedy with Exploit x Explore trade-off\n",
    "        randx = torch.rand(1)[0]\n",
    "        \n",
    "        if randx > epsilon:\n",
    "            # Exploit\n",
    "            with torch.no_grad(): # more efficient than detach()\n",
    "                state = torch.Tensor(state).to(device)\n",
    "                action_from_nn = self.nn(state)\n",
    "                action_index = torch.max(action_from_nn,0)[1] # 1 for the index\n",
    "                action = action_index.item()\n",
    "                \n",
    "                if debug:\n",
    "                    print('--> Exploit action_from_nn[',action_from_nn,'] action:',action)\n",
    "        else:\n",
    "            # Explore\n",
    "            action = env.action_space.sample()\n",
    "            if debug:\n",
    "                print('--> Explore: action:',action)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    # 3) Optimize\n",
    "    def optimize(self,state,action,new_state,reward,done):\n",
    "        # - Variable and Tensor are identical classes\n",
    "        state = torch.Tensor(state).to(device) # Convert to tensor\n",
    "        new_state = torch.Tensor(new_state).to(device)\n",
    "        reward = torch.Tensor([reward]).to(device) # since others are list, reward has to be in list format\n",
    "        \n",
    "        if done:\n",
    "            target_value = reward # episode is completed\n",
    "        else:\n",
    "            ## Bellman's equation (- Traditional way -)\n",
    "            # Q[state,action] = reward + gamma*torch.max(Q[new_state])\n",
    "        \n",
    "            # We will use NNet instead to Approx Q (- New way -)\n",
    "            new_state_values = self.nn(new_state).detach() # leave the grad\n",
    "            max_new_state_values = torch.max(new_state_values)\n",
    "            target_value = reward + gamma*max_new_state_values\n",
    "        \n",
    "        ## Q-learning: use prediction-error to update Q\n",
    "        # (-- Traditional way --)\n",
    "        # Q[state, action] = (1 - lr) * Q[state, action] \\\n",
    "        #    + lr * (reward + gamma * torch.max(Q[new_state]))\n",
    "        # (-- New way --)    \n",
    "        # Current state\n",
    "        predicted_value = self.nn(state)[action] # here we carry grad because it will update\n",
    "        # Prediction error\n",
    "        loss = self.loss(predicted_value,target_value)\n",
    "        # Backprop\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step() # update params\n",
    "        \n",
    "\n",
    "# 3) RL part\n",
    "agent = Qnet_agent()\n",
    "steps_total = []\n",
    "all_solved_nepisodes = []\n",
    "cont_steps = 0\n",
    "tic = time.time()\n",
    "for i_episode in range(num_episodes):\n",
    "    \n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        cont_steps += 1 # will keep across episodes\n",
    "        epsilon = calc_epsilon(cont_steps) \n",
    "        \n",
    "        # Action is selected\n",
    "        action = agent.select_action(state,epsilon)\n",
    "        \n",
    "        # Next environment\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        # States: [cart position,cart velocity,pole angle, pole velocity]\n",
    "        \n",
    "        # Update NNet\n",
    "        agent.optimize(state,action,new_state,reward,done)\n",
    "        \n",
    "        if debug:\n",
    "            print('Step#%d: %s, state:%s'%(step,action,new_state))\n",
    "            #print(info)\n",
    "            env.render()\n",
    "            input(\"\")\n",
    "        \n",
    "        # Prepare next iteration\n",
    "        state = new_state\n",
    "        \n",
    "        if done:\n",
    "            steps_total.append(step)\n",
    "            #print(\"Episode finished after %i steps\" % step )\n",
    "            \n",
    "            avgReward100 = sum(steps_total[-100:])/100\n",
    "            \n",
    "            if avgReward100 > score_goal:\n",
    "                print('SOLVED! After %d episodes' %(i_episode))\n",
    "                all_solved_nepisodes.append(i_episodes)\n",
    "                \n",
    "                break\n",
    "            \n",
    "            # Better reporting\n",
    "            interval = 50\n",
    "            if i_episode % interval == 0:\n",
    "                print('\\n*** Episode %i *** \\\n",
    "                \\n Avg.Reward [last %i]: %.2f, [last 100]: %.2f, [all]: %.2f\\\n",
    "                \\n epsilon: %.2f, cont_steps= %d'%\n",
    "                      (i_episode, interval,\n",
    "                      sum(steps_total[-interval:])/interval,\n",
    "                      avgReward100,\n",
    "                      sum(steps_total)/len(steps_total),\n",
    "                       epsilon, cont_steps\n",
    "                      ))\n",
    "                toc = time.time()\n",
    "                print(\"Elapsed time: \", time.strftime(\"%H:%M:%S\", time.gmtime(toc-tic)))\n",
    "            \n",
    "            break\n",
    "        \n",
    "\n",
    "print(\"Average reward: %.2f\" % (sum(steps_total)/num_episodes))\n",
    "print(\"Average reward (last 100 episodes): %.2f\" % (sum(steps_total[-100:])/100))\n",
    "print(\"Number of solved times: \", len(all_solved_nepisodes))\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title(\"Rewards\")\n",
    "plt.bar(torch.arange(len(steps_total)), steps_total, alpha=0.6, color='green')\n",
    "plt.show()\n",
    "\n",
    "env.close()\n",
    "env.env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CartPole-v0: \"Q-learning\" + Neural Net (3 layers) \n",
    "## --> DID NOT IMPROVE...\n",
    "\n",
    "- We will add 2 additional layers to input some non-linearity\n",
    "- Neural net will work as a function F, where action = F(state)\n",
    "- GOAL: be able to keep the pole for >195 steps, that is, reward>195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\n",
      "*** Episode 0 ***                 \n",
      " Avg.Reward [last 50]: 0.26, [last 100]: 0.13, [all]: 13.00                \n",
      " epsilon: 0.88, cont_steps= 13\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 50 ***                 \n",
      " Avg.Reward [last 50]: 48.62, [last 100]: 24.44, [all]: 47.92                \n",
      " epsilon: 0.03, cont_steps= 2444\n",
      "Elapsed time:  00:00:05\n",
      "\n",
      "*** Episode 100 ***                 \n",
      " Avg.Reward [last 50]: 134.80, [last 100]: 91.71, [all]: 90.93                \n",
      " epsilon: 0.02, cont_steps= 9184\n",
      "Elapsed time:  00:00:21\n",
      "\n",
      "*** Episode 150 ***                 \n",
      " Avg.Reward [last 50]: 120.72, [last 100]: 127.76, [all]: 100.79                \n",
      " epsilon: 0.02, cont_steps= 15220\n",
      "Elapsed time:  00:00:34\n",
      "\n",
      "*** Episode 200 ***                 \n",
      " Avg.Reward [last 50]: 64.46, [last 100]: 92.59, [all]: 91.76                \n",
      " epsilon: 0.02, cont_steps= 18443\n",
      "Elapsed time:  00:00:42\n",
      "\n",
      "*** Episode 250 ***                 \n",
      " Avg.Reward [last 50]: 75.26, [last 100]: 69.86, [all]: 88.47                \n",
      " epsilon: 0.02, cont_steps= 22206\n",
      "Elapsed time:  00:00:48\n",
      "\n",
      "*** Episode 300 ***                 \n",
      " Avg.Reward [last 50]: 95.80, [last 100]: 85.53, [all]: 89.69                \n",
      " epsilon: 0.02, cont_steps= 26996\n",
      "Elapsed time:  00:01:01\n",
      "\n",
      "*** Episode 350 ***                 \n",
      " Avg.Reward [last 50]: 140.54, [last 100]: 118.17, [all]: 96.93                \n",
      " epsilon: 0.02, cont_steps= 34023\n",
      "Elapsed time:  00:01:17\n",
      "\n",
      "*** Episode 400 ***                 \n",
      " Avg.Reward [last 50]: 157.50, [last 100]: 149.02, [all]: 104.48                \n",
      " epsilon: 0.02, cont_steps= 41898\n",
      "Elapsed time:  00:01:37\n",
      "\n",
      "*** Episode 450 ***                 \n",
      " Avg.Reward [last 50]: 134.62, [last 100]: 146.06, [all]: 107.82                \n",
      " epsilon: 0.02, cont_steps= 48629\n",
      "Elapsed time:  00:01:53\n",
      "Average reward: 110.66\n",
      "Average reward (last 100 episodes): 135.46\n",
      "Number of solved times:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAE/CAYAAAC0Fl50AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff2942ca470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Debug mode\n",
    "debug = False\n",
    "\n",
    "# Set CPU or GPU device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\") \n",
    "\n",
    "# Set Gym environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Set seeds\n",
    "seed_value = 23\n",
    "env.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "# PARAMS\n",
    "num_episodes = 500\n",
    "score_goal = 195 # official\n",
    "\n",
    "gamma = 0.99\n",
    "my_lr = 0.01\n",
    "nhidden = [32,32]\n",
    "\n",
    "egreedy = 0.9\n",
    "egreedy_final = 0.02\n",
    "egreedy_decay = 500\n",
    "\n",
    "# e-Greedy strategy\n",
    "def calc_epsilon(nsteps):\n",
    "    epsilon = egreedy_final + \\\n",
    "       (egreedy - egreedy_final)*math.exp(-1.*nsteps/egreedy_decay) \n",
    "    return epsilon\n",
    "\n",
    "# NEURAL NETWORK\n",
    "n_inputs = env.observation_space.shape[0] \n",
    "n_outputs = env.action_space.n\n",
    "\n",
    "# 1) Define the NN architecture\n",
    "class NeuralNet(nn.Module): # self inherits the class nn.Module\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__() # Call parent's init\n",
    "        self.linear1 = nn.Linear(n_inputs,nhidden[0]) # input\n",
    "        self.linear2 = nn.Linear(nhidden[0],nhidden[1]) # layer 1\n",
    "        self.linear3 = nn.Linear(nhidden[1],n_outputs) # layer 3\n",
    "        \n",
    "        self.activation = nn.Tanh()\n",
    "        #self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        output1 = self.linear1(x)\n",
    "        output1 = self.activation(output1)\n",
    "        output2 = self.linear2(output1)\n",
    "        output2 = self.activation(output2)\n",
    "        output3 = self.linear3(output2)\n",
    "        \n",
    "        return output3\n",
    "    \n",
    "# 2) Define the NN-agent\n",
    "class Qnet_agent():\n",
    "    # 1) Init\n",
    "    def __init__(self):\n",
    "        # a) Architecture\n",
    "        self.nn = NeuralNet().to(device)\n",
    "        # b) Loss\n",
    "        self.loss = nn.MSELoss() # linear regression\n",
    "        # c) Optim\n",
    "        self.optimizer = optim.Adam(params=self.nn.parameters(),lr=my_lr)\n",
    "        \n",
    "    # 2) Action\n",
    "    def select_action(self,state,epsilon):\n",
    "        # e-greedy with Exploit x Explore trade-off\n",
    "        randx = torch.rand(1)[0]\n",
    "        \n",
    "        if randx > epsilon:\n",
    "            # Exploit\n",
    "            with torch.no_grad(): # more efficient than detach()\n",
    "                state = torch.Tensor(state).to(device)\n",
    "                action_from_nn = self.nn(state)\n",
    "                action_index = torch.max(action_from_nn,0)[1] # 1 for the index\n",
    "                action = action_index.item()\n",
    "                \n",
    "                if debug:\n",
    "                    print('--> Exploit action_from_nn[',action_from_nn,'] action:',action)\n",
    "        else:\n",
    "            # Explore\n",
    "            action = env.action_space.sample()\n",
    "            if debug:\n",
    "                print('--> Explore: action:',action)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    # 3) Optimize\n",
    "    def optimize(self,state,action,new_state,reward,done):\n",
    "        # - Variable and Tensor are identical classes\n",
    "        state = torch.Tensor(state).to(device) # Convert to tensor\n",
    "        new_state = torch.Tensor(new_state).to(device)\n",
    "        reward = torch.Tensor([reward]).to(device) # since others are list, reward has to be in list format\n",
    "        \n",
    "        if done:\n",
    "            target_value = reward # episode is completed\n",
    "        else:\n",
    "            ## Bellman's equation (- Traditional way -)\n",
    "            # Q[state,action] = reward + gamma*torch.max(Q[new_state])\n",
    "        \n",
    "            # We will use NNet instead to Approx Q (- New way -)\n",
    "            new_state_values = self.nn(new_state).detach() # leave the grad\n",
    "            max_new_state_values = torch.max(new_state_values)\n",
    "            target_value = reward + gamma*max_new_state_values\n",
    "        \n",
    "        ## Q-learning: use prediction-error to update Q\n",
    "        # (-- Traditional way --)\n",
    "        # Q[state, action] = (1 - lr) * Q[state, action] \\\n",
    "        #    + lr * (reward + gamma * torch.max(Q[new_state]))\n",
    "        # (-- New way --)    \n",
    "        # Current state\n",
    "        predicted_value = self.nn(state)[action] # here we carry grad because it will update\n",
    "        # Prediction error\n",
    "        loss = self.loss(predicted_value,target_value)\n",
    "        # Backprop\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step() # update params\n",
    "        \n",
    "\n",
    "# 3) RL part\n",
    "agent = Qnet_agent()\n",
    "steps_total = []\n",
    "all_solved_nepisodes = []\n",
    "cont_steps = 0\n",
    "tic = time.time()\n",
    "for i_episode in range(num_episodes):\n",
    "    \n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        cont_steps += 1 # will keep across episodes\n",
    "        epsilon = calc_epsilon(cont_steps) \n",
    "        \n",
    "        # Action is selected\n",
    "        action = agent.select_action(state,epsilon)\n",
    "        \n",
    "        # Next environment\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        # States: [cart position,cart velocity,pole angle, pole velocity]\n",
    "        \n",
    "        # Update NNet\n",
    "        agent.optimize(state,action,new_state,reward,done)\n",
    "        \n",
    "        if debug:\n",
    "            print('Step#%d: %s, state:%s'%(step,action,new_state))\n",
    "            #print(info)\n",
    "            env.render()\n",
    "            input(\"\")\n",
    "        \n",
    "        # Prepare next iteration\n",
    "        state = new_state\n",
    "        \n",
    "        if done:\n",
    "            steps_total.append(step)\n",
    "            #print(\"Episode finished after %i steps\" % step )\n",
    "            \n",
    "            avgReward100 = sum(steps_total[-100:])/100\n",
    "            \n",
    "            if avgReward100 > score_goal:\n",
    "                print('SOLVED! After %d episodes' %(i_episode))\n",
    "                all_solved_nepisodes.append(i_episodes)\n",
    "                \n",
    "                break\n",
    "            \n",
    "            # Better reporting\n",
    "            interval = 50\n",
    "            if i_episode % interval == 0:\n",
    "                print('\\n*** Episode %i *** \\\n",
    "                \\n Avg.Reward [last %i]: %.2f, [last 100]: %.2f, [all]: %.2f\\\n",
    "                \\n epsilon: %.2f, cont_steps= %d'%\n",
    "                      (i_episode, interval,\n",
    "                      sum(steps_total[-interval:])/interval,\n",
    "                      avgReward100,\n",
    "                      sum(steps_total)/len(steps_total),\n",
    "                       epsilon, cont_steps\n",
    "                      ))\n",
    "                toc = time.time()\n",
    "                print(\"Elapsed time: \", time.strftime(\"%H:%M:%S\", time.gmtime(toc-tic)))\n",
    "            \n",
    "            break\n",
    "        \n",
    "\n",
    "print(\"Average reward: %.2f\" % (sum(steps_total)/num_episodes))\n",
    "print(\"Average reward (last 100 episodes): %.2f\" % (sum(steps_total[-100:])/100))\n",
    "print(\"Number of solved times: \", len(all_solved_nepisodes))\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title(\"Rewards\")\n",
    "plt.bar(torch.arange(len(steps_total)), steps_total, alpha=0.6, color='green')\n",
    "plt.show()\n",
    "\n",
    "env.close()\n",
    "env.env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
